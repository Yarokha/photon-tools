#!/usr/bin/python

from __future__ import division
import numpy as np
from photon_tools.fcs_mem import fcs_mem
from photon_tools.fcs_models import *
import matplotlib.pyplot as pl
from matplotlib import gridspec
import os.path

def load_corr(file):
    dt = [('lag','f'), ('G','f'), ('var','f')]
    usecols = None
    lines = [l for l in open(file.name).readlines() if not l.startswith('#')]
    ncols = len(lines[0].split())
    if ncols == 5:
        # favia format
        usecols = (0,3,4)
    elif ncols == 3:
        usecols = None
    else:
        raise RuntimeError('Unrecognized file format')

    d = np.genfromtxt(file, dtype=dt, usecols=usecols)
    d['G'] -= 1.0   # Subtract out offset
    return d

def random_run(args):
    (corr, models, nu) = args
    weights = np.random.uniform(0.1, 0.9, models.shape[0])
    res = fcs_mem(corr['G'], models, p0=weights, sigma=np.sqrt(corr['var']), nu=nu)
    return (nu, res)

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('file', type=argparse.FileType('r'), help='Correlation function')
    parser.add_argument('-a', '--aspect', type=float, default=10, help='Aspect ratio of observation volume')
    parser.add_argument('-t', '--start-time', type=float, default=1e-6, help='Shortest diffusion time to fit')
    parser.add_argument('-T', '--end-time', type=float, default=1, help='Longest diffusion time to fit')
    parser.add_argument('-m', '--models', type=int, default=500, help='Number of models')
    parser.add_argument('-N', '--nu', type=float, default=1e-3, help='Regularization parameter')
    parser.add_argument('-n', '--runs', type=int, default=10, help='How many randomly initialized fits to run')
    args = parser.parse_args()
    Nmodels = args.models

    corr = load_corr(args.file)
    corr = corr[corr['lag'] >= 1e-6]

    tauDs = np.logspace(np.log10(args.start_time), np.log10(args.end_time), Nmodels)
    models = np.vstack([three_dim_diffusion(lag=corr['lag'], aspect=args.aspect, n=1, tauD=tauD)
                        for tauD in tauDs])

    gs = gridspec.GridSpec(3,2, width_ratios=[3,1], height_ratios=[3,1,1])
    plots = pl.subplot(gs[0,0])
    residuals = pl.subplot(gs[1,0])
    weights = pl.subplot(gs[2,0])
    legend = gs[:,1]

    plots.errorbar(corr['lag'], corr['G'], yerr=np.sqrt(corr['var']), c='k', label='observed')

    import multiprocessing
    pool = multiprocessing.Pool()
    nus = [args.nu] * args.n_runs
    runs = map(random_run, [(corr, models, nu) for nu in nus])

    for (nu, res) in runs:
        resid = (corr['G']  - np.dot(models.T, res))**2 / corr['var']
        chiSqr = np.sum(resid) / (corr.shape[0] - Nmodels)
        entropy = np.sum(-res * np.log(res))
        print nu, chiSqr, entropy
        l = plots.plot(corr['lag'], np.dot(models.T, res), label=r'$\nu=%1.2g (\chi^s=%1.4f, S=%1.2f)$' % (nu, chiSqr, entropy))
        color = l[0].get_color()
        residuals.plot(tauDs, resid, '+', c=color)
        weights.plot(tauDs, res, '-', c=color)

    plots.set_xscale('log')
    plots.set_ylabel(r'$G(\tau)$')
    plots.axhline(0, c='k')
    residuals.set_xscale('log')
    residuals.axhline(0, c='k')
    weights.set_xscale('log')
    weights.set_xlabel(r'$\tau$ (seconds)')
    plots.set_title(os.path.basename(args.file.name))
    bbox = legend.get_position(pl.gcf())
    plots.legend(loc='upper left',
                 bbox_to_anchor=bbox,
                 bbox_transform=pl.gcf().transFigure,
                 mode='expand', fontsize='x-small', ncol=1,
                 frameon=False)
    pl.savefig('%s.png' % args.file.name)

if __name__ == '__main__':
    main()
