#!/usr/bin/env python

from __future__ import division
import numpy as np
import squmfit
from squmfit import Fit, model, Argument
from matplotlib import pyplot as pl
from collections import namedtuple

class Aniso(object):
    """ Anisotropy detection channels """
    def __init__(self, par, perp):
        self.par = par
        self.perp = perp

    def map(self, f):
        return Aniso(f(self.par), f(self.perp))

@model
def exponential(t, rate, amplitude):
    """ Note that this should contain a prefactor of `rate` that has
    been omitted to minimize parameter covariance """
    return amplitude * np.exp(-t * rate)

@model
def interpolate_irf(response, period, offset):
    """
    An instrument response function which is interpolated and
    (possibly) shifted in time.

    Evaluates to an array of the same shape as `response`.

    :type response: array of shape (N,)
    :param response: Instrument response
    :param period: The period of the instrument response
    :param offset: The temporal offset between the response and
        the measured curve (in bins)
    """

    from scipy.interpolate import interp1d

    shift = len(response) % period
    periodic_irf_f = interp1d(np.arange(len(response)), response,
                              assume_sorted=True)
    ts = np.arange(3 * len(response)) + shift + offset
    ts %= period
    # sometimes numerical error gives us values slightly outside
    # the interpolation range, be sure to clamp these
    ts = np.clip(ts, a_min=0, a_max = len(response) - 1)
    interpolated_irf = periodic_irf_f(ts)
    return interpolated_irf

@model
def convolved_model(response, model):
    """
    Convolve a model with a response.

    :type response: :class:`InterpolatedIrf`
    :param response: The instrument response
    :type model: :class:`squmfit.Expr`
    :param model: The model we are trying to evaluate
    """
    from scipy.signal import fftconvolve
    a = fftconvolve(response, model, 'same')
    return a[len(model) : 2*len(model)]

def estimate_rep_rate(irf):
    """ Estimate excitation repetition rate (measured in bins) from IRF """
    middle = (np.max(irf) - np.min(irf)) / 2 + np.min(irf)
    idxs, = np.nonzero(np.logical_and(irf[:-1] < middle, middle < irf[1:]))
    a,b = sorted(idxs)[:2]
    period = b - a
    debug = False
    if debug:
        pl.plot(irf)
        pl.axhline(middle, c='k')
        pl.axvline(a, c='g')
        pl.axvline(b, c='g')
        pl.yscale('log')
        pl.show()
    return period

def normalize_irfs(irfs):
    """
    Subtract background from and normalize IRF

    :type irfs: Aniso of histograms
    :rtype: Aniso of histograms
    """
    def background_subtract(irf):
        bg = np.median(irf)
        print('IRF background = %1.2f' % bg)
        return irf - bg

    irfs = irfs.map(background_subtract)

    # Fix normalization of IRF
    return irfs.map(lambda x: x / sum(x))

def fit(irfs, corrs, jiffy_ps, exc_period, n_components, periods=1, **kwargs):
    """
    :type irfs: :class:`Aniso` of arrays
    :param irfs: Normalized IRF histograms
    :type corrs: list of :class:`Aniso`s
    :param corrs: Fluorescence histograms
    :type jiffy_ps: int
    :param jiffy_ps: Bin width in picoseconds
    :type exc_period: int
    :param exc_period: Excitation period measured in bins
    :type n_components: int
    :param n_components: Number of exponential decay components to fit against
    :type periods: int
    :param periods: Number of periods to fit against
    :param kwargs: Other keyword arguments passed to `analyze`
    :rtype: tuple of two :class:`FitResults`
    """
    jiffy = jiffy_ps * 1e-12
    n = periods * exc_period
    irfs = irfs.map(lambda x: x[:n])

    # Run the fit first to get the parameters roughly correct, then
    # then infer the period
    res1 = analyze(irfs, corrs, exc_period, n_components, jiffy_ps, **kwargs)
    res2 = analyze(irfs, corrs, exc_period, n_components, jiffy_ps,
                   free_period=True, params0=res1.params, **kwargs)
    return res1, res2

def analyze(irfs, corrs, exc_period, n_components, jiffy_ps,
            params0=None, free_period=False, trim_end=0,
            exc_leakage=False, imbalance=None, indep_aniso=False):
    """
    Fit a set of anisotropy data with the given IRF and model

    :type irfs: :class:`Aniso` of arrays
    :param irfs: Normalized IRF histograms
    :type corrs: :class:`Aniso` of :class:`file`s
    :type exc_period: `float`
    :param exc_period: the approximate excitation period in bins
    :type n_components: `int`
    :param n_components: the number of exponential components to fit against
    :type jiffy_ps: `int`
    :param jiffy_ps: the channel width in picoseconds
    :param params0: The initial parameters to fit with
    :type free_period: `bool`
    :param free_period: Whether to fit the excitation period
    :type trim_end: `int`
    :param trim_end: Number of bins to drop off of the end of the correlations.
       This is to work around the spurious bins with low counts near the end of
       histograms produced by the Picoharp 300.
    :type exc_leakage: `bool`
    :param exc_leakage: Whether to include leakage of the excitation (modelled by
       the IRF) in the detection model.
    :type imbalance: `float` or None
    :param imbalance: Fix detector imbalance factor g
    :type indep_aniso: `bool`
    :param indep_aniso: Whether to fit a different rotational
       coherence time for each curve.
    """
    fit = Fit()
    lag = Argument('t')

    offset_par = fit.param('offset-par', 0)
    offset_perp = fit.param('offset-perp', 0)
    period = fit.param('period', exc_period)

    # Build decay model
    rates = []
    for i in range(n_components):
        tau = 1000 + 1000*i
        rate = fit.param('lambda%d' % i, initial=1/tau)
        rates.append(rate)

    # Parameters for anisotropy model
    r0 = fit.param('r0', initial=0.4)
    if imbalance is None:
        imbalance = fit.param('g', initial=1)
    if not indep_aniso:
        rate_rot = fit.param('lambda_rot', initial=1/100)

    for pair_idx,corr in enumerate(corrs):
        if indep_aniso:
            rate_rot = fit.param('lambda_rot%d' % pair_idx, initial=1/100)

        def read_histogram(path):
            # read histogram
            corr = np.genfromtxt(path)[:,1]
            n = len(irfs.par) # FIXME?
            assert len(corr) >= n
            corr = corr[:n - trim_end] # FIXME?
            return corr

        # generate fluorescence decay model
        par = read_histogram(corr.par.name)
        perp = read_histogram(corr.perp.name)
        assert len(par) == len(perp)

        decay_models = []
        initial_amp = np.max(par) / np.sum(par)
        for comp_idx, rate in enumerate(rates):
            times = jiffy_ps * np.arange(par.shape[0])
            amp = fit.param('c%d_amplitude%d' % (pair_idx, comp_idx), initial=initial_amp)
            decay_models.append(exponential(t=lag, rate=rate, amplitude=amp))
        decay_model = sum(decay_models)

        # IRF leakage
        leakage = 0
        if exc_leakage:
            leakage = fit.param('c%d_leakage' % pair_idx, initial=0.1)

        def add_curve(corr, name, rot_model, offset, norm, irf):
            times = jiffy_ps * np.arange(corr.shape[0])

            # generate weights
            weights = np.zeros_like(corr)
            weights[corr != 0] = 1 / np.sqrt(corr[corr != 0])

            # generate model
            iirf = interpolate_irf(response=irf,
                                   period=period if free_period else exc_period,
                                   offset=offset)
            convolved = convolved_model(response=iirf, model=decay_model * rot_model(times))
            model = norm * convolved
            if leakage != 0:
                model = model + leakage * iirf.map(lambda a: a[:len(corr)])
            fit.add_curve(name, np.sum(corr) * model, corr, weights=weights, t=times)

        add_curve(corr = par,
                  rot_model = lambda times: 1 + 2 * r0 * np.exp(-rate_rot * times),
                  norm = 1,
                  offset = offset_par,
                  name = corr.par.name+'_par',
                  irf = irfs.par)
        add_curve(corr = perp,
                  rot_model = lambda times: 1 - r0 * np.exp(-rate_rot * times),
                  norm = imbalance,
                  offset = offset_perp,
                  name = corr.perp.name+'_perp',
                  irf = irfs.perp)

    return fit.fit(params0)

def print_params(p, corrs, ncomponents):
    print '  irf period', p['period']
    print '  irf offset (parallel)', p['offset-par']
    print '  irf offset (perpendicular)', p['offset-perp']
    if 'g' in p: print '  g', p['g']
    print '  r0', p['r0']
    if 'lambda_rot' in p:
        print '  tau_rot', 1/p['lambda_rot']

    for comp_idx in range(ncomponents):
        rate = p['lambda%d' % comp_idx]
        print '  Component %d' % comp_idx
        print '    tau', 1/rate

    for pair_idx,pair in enumerate(corrs):
        print '  Sample %d (par=%s, perp=%s)' % (pair_idx, pair.par.name, pair.perp.name)
        leakage = 'c%d_leakage' % pair_idx
        if leakage in p:
            print '    leakage', '%1.2g' % p[leakage]
        if ('lambda_rot%d' % pair_idx) in p:
            print '    tau_rot', 1/p['lambda_rot%d' % pair_idx]

        ampls = [ p['c%d_amplitude%d' % (pair_idx, comp_idx)] / rate
                  for comp_idx in range(ncomponents) ]
        for comp_idx in range(ncomponents):
            rate = p['lambda%d' % comp_idx]
            frac = ampls[comp_idx] / sum(ampls)
            print '    amplitude%d' % comp_idx, '%1.2f    (%2.1f%%)' % (ampls[comp_idx], frac * 100)

def main():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('corr', metavar='FILE', nargs='+', type=argparse.FileType('r'),
                        help="correlation function")
    parser.add_argument('--irf', '-i', metavar='FILE', action='append', type=argparse.FileType('r'),
                        help='instrument response function')
    parser.add_argument('--components', '-c', type=int, default=1,
                        help='number of fit components')
    parser.add_argument('--rep-rate', '-r', type=float,
                        help='pulse repetition rate (Hertz)')
    parser.add_argument('--periods', '-p', type=int, default=1,
                        help='how many pulse periods we should fit to')
    parser.add_argument('--output', '-o', type=argparse.FileType('w'),
                        help='where to send output')
    parser.add_argument('--no-offset', action='store_true',
                        help='do not fit temporal offset between data and IRF')
    parser.add_argument('-j', '--jiffy', type=float,
                        help='Bin width in seconds')
    parser.add_argument('-e', '--exc-leakage', action='store_true',
                        help='Whether to model leakage of excitation into detection channels')
    parser.add_argument('-J', '--json', type=argparse.FileType('w'),
                        help='JSON output file')
    parser.add_argument('--imbalance', '-g', type=float,
                        help='Fix detector imbalance factor g')
    parser.add_argument('-A', '--indep-aniso',
                        help='Fit per-dataset rotational coherence models')
    parser.add_argument('-R', '--sep-resid', action='store_true',
                        help='Plot residuals on separate per-dataset axes')
    args = parser.parse_args()

    corrs = [Aniso(a,b) for a,b in zip(args.corr[::2], args.corr[1::2])]

    irfs = [np.genfromtxt(irf, dtype=None, names='time,counts') for irf in args.irf]
    if len(irfs) != 2:
        raise RuntimeError('Expected two IRFs')
    times = irfs[0]['time']
    irfs = [irf['counts'] for irf in irfs]
    irfs = normalize_irfs(Aniso(irfs[0], irfs[1]))

    # Determine the channel width (jiffy)
    if args.jiffy is not None:
        jiffy_ps = args.jiffy / 1e-12
    else:
        jiffy_ps = (times[1] - times[0]) # in picoseconds

    # Determine the pulse repetition rate
    if args.rep_rate is None:
        period = estimate_rep_rate(irfs.par)
    else:
        period = int(1e12 / args.rep_rate / jiffy_ps) # period in ticks

    print 'Period', period, 'bins'
    print 'Channel width', jiffy_ps, 'ps'

    res0, res = fit(irfs, corrs, jiffy_ps, period, args.components,
                    periods=args.periods, trim_end=5,
                    exc_leakage=args.exc_leakage,
                    imbalance=args.imbalance,
                    indep_aniso=args.indep_aniso)

    # Present results
    print
    print 'Initial parameters'
    print_params(res0.initial.params, corrs, args.components)

    print
    print 'Fitted parameters'
    print_params(res.params, corrs, args.components)

    # Fix covariance
    for comp_idx1 in range(args.components):
        for pair_idx1,_ in enumerate(args.corr):
            for comp_idx2 in range(args.components):
                for pair_idx2,_ in enumerate(args.corr):
                    p1 = 'c%d_amplitude%d' % (pair_idx1, comp_idx1)
                    p2 = 'c%d_amplitude%d' % (pair_idx2, comp_idx2)
                    rate1 = res.params['lambda%d' % comp_idx1]
                    rate2 = res.params['lambda%d' % comp_idx2]
                    #res.covar[p1][p2] *= rate1 * rate2

    print
    print 'Reduced chi-squared'
    for name, curve in sorted(res.curves.items()):
        print '  %-15s     %1.3g' % (name, curve.reduced_chi_sqr)

    print
    print 'Standard error'
    if res.stderr is not None:
        for param, err in res.stderr.items():
            print '  %-15s     %1.2g' % (param, err)
    else:
        print "  Failed to compute due to flat axis"

    print
    print 'Correlations (coefficients less than 0.2 omitted)'
    if res.correl is not None:
        correls = {(param1,param2): res.correl[param1][param2]
                   for param1 in res.params.keys()
                   for param2 in res.params.keys()
                   if param1 < param2}
        for (p1,p2), c in sorted(correls.items(), key=lambda ((a,b),c): c, reverse=True):
            if abs(c) > 0.2:
                print '  %-15s / %-15s       %1.2f' % (p1, p2, c)
    else:
        print "  Failed to compute due to flat axis"

    import matplotlib.gridspec as gridspec
    if args.sep_resid:
        ncurves = len(corrs)
        gs = gridspec.GridSpec(1 + ncurves, 2,
                               width_ratios=[3,1],
                               height_ratios=[4] + [1]*ncurves)
    else:
        gs = gridspec.GridSpec(2, 2, width_ratios=[3,1], height_ratios=[3,1])

    plots = pl.subplot(gs[0, 0])
    legend = gs[0:1, 1]
    if args.sep_resid:
        residuals = {pair_idx: pl.subplot(gs[1+pair_idx, 0]) for pair_idx,_ in enumerate(corrs)}
    else:
        resid = pl.subplot(gs[1, 0])
        residuals = {pair_idx: resid for pair_idx,_ in enumerate(corrs)}

    color_cycle = pl.rcParams['axes.color_cycle']
    for pair_idx, aniso in enumerate(corrs):
        for name, ch in [(aniso.par.name, 'par'), (aniso.perp.name, 'perp')]:
            cres = res.curves['%s_%s' % (name, ch)]
            color = color_cycle[pair_idx % len(color_cycle)]
            times = jiffy_ps / 1000 * np.arange(cres.fit.shape[0])
            sym = '+' if ch == 'par' else 'x'
            label = name if ch == 'par' else None
            alpha = 0.1
            kwargs = {'color': color, 'markersize': 1.5}
            plots.plot(times, cres.curve.data, sym, alpha=alpha, **kwargs)
            plots.plot(times, cres.fit, label=label, alpha=0.6, **kwargs)
            residuals[pair_idx].plot(times, cres.residuals, sym, alpha=alpha/3, **kwargs)

    plots.set_ylabel('number of occurences')
    residuals[len(corrs)-1].set_xlabel('time (ns)')
    for k,axes in residuals.items():
        axes.set_ylabel('residual')
        axes.axhline(0, color='k')
    plots.set_yscale('log')

    import matplotlib.lines as mlines
    handles, labels = plots.get_legend_handles_labels()
    handles = [
        mlines.Line2D([], [], color='k', label='fit'),
        mlines.Line2D([], [], color='k', marker='+', label='parallel'),
        mlines.Line2D([], [], color='k', marker='x', label='perpendicular'),
        mlines.Line2D([], [], alpha=0, label=''),  # Spacer
    ] + handles
    bbox = legend.get_position(pl.gcf())
    plots.legend(handles=handles, loc='upper left',
                 bbox_to_anchor=bbox,
                 bbox_transform=pl.gcf().transFigure,
                 mode='expand', fontsize='small', ncol=1, frameon=False)

    if args.json is not None:
        import json
        json.dump(res.params, args.json)

    if args.output is not None:
        pl.savefig(args.output, figsize=(5,5), dpi=600)
    else:
        pl.show()

if __name__ == '__main__':
    main()
