#!/usr/bin/python

import argparse
from argparse import ArgumentParser
import warnings
import os.path

from photon_tools.correlate import corr, autocorr, corr_chunks
from photon_tools.io import read_photons

import numpy as np
import math

try:
    import matplotlib
    matplotlib.use('Agg')
    from matplotlib import pyplot as pl
    from matplotlib import cm
    mpl_available = True
except:
    mpl_available = False

verbose = False

parser = ArgumentParser(description='Compute and plot correlation functions of photon timestamps',
                        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('files', metavar='FILE', type=argparse.FileType('r'), nargs='+',
                    help='Input timestamp files')
parser.add_argument('-a', '--a-channel', type=int, default=0,
                    help='Channel to run correlate')
parser.add_argument('-b', '--b-channel', type=int, default=1,
                    help='Channel to run correlate')
parser.add_argument('-E', '--min-lag', type=float, default=5e-7,
                    help='Smallest lag to compute')
parser.add_argument('-L', '--max-lag', type=float, default=1,
                    help='Longest lag to compute')
parser.add_argument('-n', '--nchunks', type=int, default=10,
                    help='Number of subsamples to split data into for variance computation. If 1 the Wohland estimator is used.')
parser.add_argument('-O', '--output', default='.',
                     help='Output directory')
parser.add_argument('--chunks', action='store_true', help='Produce file containing chunks')
parser.add_argument('--plot-chunks', action='store_true', help='Produce plot showing correlation functions of subsamples')
parser.add_argument('-f', '--fineness', type=int, default=8,
                    help='Number of lags per octave')
parser.add_argument('-v', '--verbose', action='store_true',
                    help='Produce debugging output')
parser.add_argument('-l', '--label', type=str, default='corr',
                    help='Descriptive label for dataset shown in plot')
parser.add_argument('-j', '--jiffy', type=float, default=None,
                    help='Acquisition timebase period')
parser.add_argument('-s', '--single', action='store_true',
                    help="Produce only cross-correlations of given channels, skipping auto-correlations")
parser.add_argument('-p', '--plot', action='store_true',
                    help='Plot each computed correlation function')
parser.add_argument('-P', '--plot-type', default='png',
                    help='File format of plot output (svg, png, pdf, or ps)')
parser.add_argument('-t', '--start-time', default=None, type=str,
                    help='Start time of usable data (seconds). Use + and - to indicate times relative to first and last timestamps of dataset, respectively.')
parser.add_argument('-T', '--stop-time', default=None, type=str,
                    help='Stop time of usable data (seconds). Use + and - to indicate times relative to first and last timestamps of dataset, respectively.')
parser.add_argument('-e', '--exclude', action='append', metavar='T-T',
                    help='Exclude a range of times (given in seconds)')
parser.add_argument('-A', '--afterpulse', default=None, type=argparse.FileType('r'),
                    metavar='FILE',
                    help='Uncorrelated timestamps for afterpulsing correction')
parser.add_argument('--engine', default=None,
                    help='Which correlator engine to use (hphoton or favia)')
parser.add_argument('--afterpulse-cutoff', default=None,
                    help="Don't apply afterpulsing correction beyond given lag")
args = parser.parse_args()
verbose = args.verbose

def parse_exclude(s):
    start, end = s.split('-')
    return (float(start), float(end))
exclude = [parse_exclude(e) for e in args.exclude] if args.exclude is not None else []

correlations = [(args.a_channel, args.a_channel, 'acorr-%d' % args.a_channel),
                (args.b_channel, args.b_channel, 'acorr-%d' % args.b_channel),
                (args.a_channel, args.b_channel, 'xcorr-%d-%d' % (args.a_channel, args.b_channel))
               ]
if args.single:
    correlations = [(args.a_channel, args.b_channel, args.label)]

def get_jiffy(timestamps):
    jiffy = timestamps.jiffy
    if args.jiffy is not None:
        jiffy = args.jiffy
    if jiffy is None:
        jiffy = 1. / 128e6
        print "Couldn't identify jiffy of file. Defaulting to %e s" % jiffy
    return jiffy

def afterpulsing_correction(ch):
    """
    Afterpulsing correction as described by,

      M. Zhao, L. Jin, B. Chen, et al.
      "Afterpulsing and its correction in fluorescence correlation spectroscopy
      experiments." _Applied Optics_ (2003)
    """
    f = read_photons.open(args.afterpulse.name)
    d = f.channel(ch)
    jiffy = get_jiffy(f)
    kwargs = {
        'jiffy': jiffy,
        'min_lag': args.min_lag,
        'max_lag': args.max_lag,
        'fineness': args.fineness,
        'engine': args.engine,
    }

    # TODO: Verify compatible jiffy
    uncorr_G = autocorr(d, **kwargs)
    mean_I = 1. * len(d) / (d[-1] - d[0])
    afterpulse_corr = (uncorr_G['G'] - 1) * mean_I / jiffy
    afterpulse_var = uncorr_G['var'] * (mean_I / jiffy)**2
    cutoff = args.afterpulse_cutoff
    if cutoff is not None:
        afterpulse_corr[uncorr_G['lag'] > cutoff] = 0
        afterpulse_var[uncorr_G['lag'] > cutoff] = 0
    return (afterpulse_corr, afterpulse_var)

if not os.path.isdir(args.output):
    os.makedirs(args.output)

# Memoize the correlation functions for afterpulsing correction
afterpulse_cache = {}

for file in args.files:
    for (ac,bc,label) in correlations:
        fname = os.path.basename(file.name)
        output_base = os.path.join(args.output, fname+'.'+label)
        f = read_photons.open(file.name)

        jiffy = get_jiffy(f)
        ad, bd = f.channel(ac), f.channel(bc)
        na, nb = len(ad), len(bd)
        for (start,end) in exclude:
            ad = ad[np.logical_or(ad < start / jiffy, ad > end / jiffy)]
            bd = bd[np.logical_or(bd < start / jiffy, bd > end / jiffy)]

        if len(ad) == 0 or len(bd) == 0:
            print "No data in one channel, skipping"
            continue

        t0 = min(ad[0], bd[0])
        t1 = max(ad[-1], bd[-1])
        if args.start_time is not None:
            if args.start_time[0] == '-':
                start_time = t1 - float(args.start_time[1:]) / jiffy
            elif args.start_time[0] == '+':
                start_time = t0 + float(args.start_time[1:]) / jiffy
            else:
                start_time = float(args.start_time) / jiffy
            ad = ad[ad >= start_time]
            bd = bd[bd >= start_time]

        if args.stop_time is not None:
            if args.stop_time[0] == '-':
                stop_time = t1 - float(args.stop_time[1:]) / jiffy
            elif args.stop_time[0] == '+':
                stop_time = t0 + float(args.stop_time[1:]) / jiffy
            else:
                stop_time = float(args.stop_time) / jiffy
            ad = ad[ad < stop_time]
            bd = bd[bd < stop_time]

        print label

        print '  %20s, channel %d:' % (fname, ac)
        print '    %d events, %d after filtering' % (na, len(ad))
        durA = ad[-1] - ad[0]
        print '    duration = %d = %1.2f seconds' % (durA, (durA * jiffy))

        print '  %20s, channel %d:' % (fname, bc)
        print '    %d events, %d after filtering' % (nb, len(bd))
        durB = bd[-1] - bd[0]
        print '    duration = %d = %1.2f seconds' % (durB, (durB * jiffy))

        kwargs = {
            'jiffy': jiffy,
            'min_lag': args.min_lag,
            'max_lag': args.max_lag,
            'fineness': args.fineness,
            'verbose': args.verbose,
            'engine': args.engine,
        }

        c = None
        nchunks = args.nchunks

        if nchunks > 1:
            if durA / nchunks < 10 * args.max_lag \
               or durB / nchunks < 10 * args.max_lag:
                orig = nchunks
                nchunks = dur / nchunks / args.max_lag / 10
                warnings.warn('%s: Data set too short to compute %d chunks, will compute %d instead' % (fname, orig, nchunks))
            c,chunks = corr_chunks(ad, bd, n=nchunks, **kwargs)
            if args.chunks:
                np.savetxt(fname+'.chunks.'+label, np.vstack([c['lag'], chunks]).T)
        else:
            c = corr(ad, bd, **kwargs)

        if args.afterpulse is not None:
            if ac != bc:
                warnings.warn("Can only perform afterpulsing correction on autocorrelations, won't be performed")
            else:
                mu = 1.0 * na / durA
                if ac not in afterpulse_cache:
                    afterpulse_cache[ac] = afterpulsing_correction(ac)
                afterpulse_corr, afterpulse_var = afterpulse_cache[ac]
                c['G'] -= jiffy / mu * afterpulse_corr
                c['var'] += (jiffy / mu)**2 * afterpulse_var

        print '  G(%1.2e s) = %1.3f' % (c[0]['lag'], c[0]['G'])
        print '  G(%1.2e s) = %1.3f' % (c[-1]['lag'], c[-1]['G'])
        print

        with open(output_base, 'w') as f:
                f.write('# lag            G(tau)            variance\n')
                np.savetxt(f, c)

        if args.plot:
            if not mpl_available:
                raise RuntimeError('Matplotlib import failed, plotting not available')
            pl.clf()
            pl.xscale('log')
            pl.xlabel('Lag (s)')
            pl.ylabel('Correlation')
            pl.axhline(1, color='0.7')
            if nchunks > 1 and args.plot_chunks:
                for i in range(chunks.shape[0]):
                    pl.scatter(c['lag'], chunks[i,:], marker='+', alpha=0.6,
                               color='%f' % (0.3 + i * 0.7 / chunks.shape[0]))
                pl.scatter(c['lag'], np.mean(chunks, axis=0), marker='+', color='k')

            pl.errorbar(c['lag'], c['G'], yerr=np.sqrt(c['var']), fmt='+')
            pl.savefig(output_base+'.'+args.plot_type)

